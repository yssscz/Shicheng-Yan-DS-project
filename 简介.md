
# Rotten Tomatoes影评情感分析报告

## 项目成员
- 闫世成（Shicheng Yan）

## 摘要
本研究评估了基于Transformer的BERT和GPT-2模型在Rotten Tomatoes影评数据集上的情感分析表现。通过实验对比数据清洗策略与类别加权优化的影响，项目揭示了在降噪、类别平衡和模型性能之间的权衡。结果显示，BERT在未清洗数据上应用类别权重后，表现最佳，凸显了保留关键信息和解决类别不平衡的重要性。

## 1. 引言

### 1.1 问题陈述
本项目旨在将影评短语分类为五种情感类别之一：消极、略消极、中性、略积极和积极。情感分析广泛应用于推荐系统、社交媒体分析和市场调研等领域。

### 1.2 项目动机
理解情感对于优化用户体验、分析舆情和为电商、娱乐、客户服务等行业提供决策支持至关重要。然而，数据噪声、类别不平衡和模型选择等问题仍是挑战。

## 2. 数据集概述

### 2.1 数据来源
该数据集由影评短语及其对应情感标签组成，总计约156,000条短语。

### 2.2 类别分布
- 中性占比51%，为最大类别；
- 正面和负面评论分别约占4%和10%，属于严重不平衡数据；
- 类别失衡使得模型容易偏向中性类别，降低整体泛化能力。

## 3. 方法论

### 3.1 数据预处理
**降噪处理：**
- 去除标点、特殊字符与停用词；
- 过滤掉过短、缺乏情感信息的中性短语；

**权衡分析：**
- 虽然降噪提高了模型对细粒度情感的区分度，但也可能删除了关键的上下文信息，尤其影响中性类别的判断。

### 3.2 模型介绍
**BERT：**
- 一种双向Transformer模型，擅长捕捉文本上下文；
- 经过微调以适配情感分类任务；

**GPT-2：**
- 一种生成型Transformer模型，此处用于情感分类；
- 需进行额外填充处理以适配批量训练；

### 3.3 类别权重优化
- 使用加权损失函数缓解类别不平衡问题；
- 增强模型对正面和负面等少数类别的识别能力；

### 3.4 评估指标
- Accuracy（准确率）：整体预测正确率；
- F1分数：
  - Macro-F1：各类权重相等；
  - Weighted F1：按类别样本数加权平均；

## 4. 实验结果

### 4.1 模型表现汇总

| 模型 | 数据集 | 准确率 | Macro-F1 | Weighted F1 |
|------|--------|--------|-----------|--------------|
| BERT | 清洗后 | 63.93% | 60%       | 64%          |
| GPT-2 | 清洗后 | 61.14% | 56%       | 61%          |
| BERT | 未清洗 | 69.80% | 63%       | 70%          |
| GPT-2 | 未清洗 | 68.75% | 59%       | 69%          |
| BERT (加权) | 未清洗 | 70.04% | 63%       | 70%          |

### 4.2 主要观察

**数据清洗：**
- 提升了模型对细粒度情感（如略积极）的区分度，但削弱了对中性类别的识别能力；

**类别加权：**
- 显著增强了BERT对少数类的识别性能，提高了Macro-F1分数；

**模型对比：**
- BERT在所有情形下表现均优于GPT-2，说明其对短文本上下文的捕捉能力更强；

## 5. 讨论

### 5.1 关键结论
- 清洗策略需权衡：过度清洗可能导致情感信息丢失；
- 类别加权有效：可在不牺牲整体准确率的情况下提升少数类性能；
- 模型选择关键：BERT的双向上下文捕捉机制更适用于情感分类任务；

### 5.2 局限性
- 数据失衡依旧显著，正负类样本不足限制了模型泛化能力；
- GPT-2对短文本和类别不均任务需进一步调优；

## 6. 结论与未来方向

### 总结
本项目展示了数据预处理与模型优化在情感分析中的重要性。实验表明：
- BERT在未清洗数据上进行类别加权优化后，表现最佳；
- 清洗策略应谨慎，避免丢失含有情感信息的文本特征；

### 未来工作方向
- 半监督学习：引入未标注数据，增强对少数类的表示；
- 集成模型：结合BERT与GPT-2的优点，提升分类鲁棒性；
- 自动化清洗：构建动态降噪算法，兼顾上下文保留与信息提纯。
