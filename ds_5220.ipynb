{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4gWNbx2EH/agiZoKz4BB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yssscz/Shicheng-Yan-DS-project/blob/main/ds_5220.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "train_data = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "test_data = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
        "\n",
        "# check\n",
        "print(train_data.head())\n",
        "\n",
        "\n",
        "# get the text and label\n",
        "train_texts = train_data[\"Phrase\"].tolist()\n",
        "train_labels = train_data[\"Sentiment\"].tolist()\n",
        "\n",
        "# split dataset\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# test dataset\n",
        "test_texts = test_data[\"Phrase\"].tolist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQBPN-S5gaS6",
        "outputId": "1fe6b81b-2ab4-4de3-8cf9-e87b92783f55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PhraseId  SentenceId                                             Phrase  \\\n",
            "0         1           1  A series of escapades demonstrating the adage ...   \n",
            "1         2           1  A series of escapades demonstrating the adage ...   \n",
            "2         3           1                                           A series   \n",
            "3         4           1                                                  A   \n",
            "4         5           1                                             series   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          2  \n",
            "2          2  \n",
            "3          2  \n",
            "4          2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(train_data['Sentiment'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqwEOyTZVhqd",
        "outputId": "a3cedbf4-ff2f-41ac-e7ec-f58e040646fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment\n",
            "2    79582\n",
            "3    32927\n",
            "1    27273\n",
            "4     9206\n",
            "0     7072\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # remove special characters\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "F5m2b94qXbVO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  # remove stopwords\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1c19KD_ZS3n",
        "outputId": "16aee292-ec92-4ee1-ba67-e9906c69de25"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_pipeline(text):\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "0nQZNVmKco_3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"Cleaned_Phrase\"] = train_data[\"Phrase\"].apply(clean_text_pipeline)\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-7F2yRjc6t_",
        "outputId": "24122ea9-46d1-42a5-86eb-f4d2e048e295"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PhraseId  SentenceId                                             Phrase  \\\n",
            "0         1           1  A series of escapades demonstrating the adage ...   \n",
            "1         2           1  A series of escapades demonstrating the adage ...   \n",
            "2         3           1                                           A series   \n",
            "3         4           1                                                  A   \n",
            "4         5           1                                             series   \n",
            "\n",
            "   Sentiment                                     Cleaned_Phrase  \n",
            "0          1  A series escapades demonstrating adage good go...  \n",
            "1          2  A series escapades demonstrating adage good goose  \n",
            "2          2                                           A series  \n",
            "3          2                                                  A  \n",
            "4          2                                             series  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates_and_empty(data): # clean dataset\n",
        "\n",
        "    data = data[data['Cleaned_Phrase'].str.strip() != \"\"]\n",
        "\n",
        "    data = data.drop_duplicates(subset=['Cleaned_Phrase'])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "NhRj8bafefeo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_single_word_and_sentiment(data):\n",
        "# Delete all rows where the Cleaned_Phrase column contains only one word and the Sentiment value is 2.\n",
        "    data['Cleaned_Phrase'] = data['Cleaned_Phrase'].fillna(\"\")\n",
        "\n",
        "    data = data[~((data['Cleaned_Phrase'].str.split().str.len() <= 2) & (data['Sentiment'] == 2))]\n",
        "\n",
        "    return data\n",
        "cleaned_train_data2 = clean_single_word_and_sentiment(cleaned_train_data)"
      ],
      "metadata": {
        "id": "bnqiWSWPglTl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_train_data2['Sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTvODIWEg0eT",
        "outputId": "b6da68b4-8381-462f-bc36-33635332db2f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment\n",
            "2    19436\n",
            "3    18901\n",
            "1    15953\n",
            "4     5331\n",
            "0     4139\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# cleaned dataset split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    cleaned_train_data2['Cleaned_Phrase'],\n",
        "    cleaned_train_data2['Sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ue0NGYbWicE5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Data preprocessing function\n",
        "def preprocess_function(texts, labels=None):\n",
        "    encodings = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=256)\n",
        "    if labels is not None:\n",
        "        encodings[\"labels\"] = torch.tensor(list(labels))\n",
        "    return encodings\n",
        "\n",
        "# Using the cleaned dataset\n",
        "train_encodings = preprocess_function(X_train, y_train)\n",
        "val_encodings = preprocess_function(X_val, y_val)\n",
        "\n",
        "# Load the BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels=5)\n",
        "\n",
        "# Define Trainer arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_results\",\n",
        "    overwrite_output_dir=True,\n",
        "    run_name=\"bert_finetune_experiment\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,  # Reduce batch size to save GPU memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./bert_logs\",\n",
        ")\n",
        "\n",
        "# Define custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings)\n",
        "val_dataset = CustomDataset(val_encodings)\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Validation set predictions\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = predictions.predictions.argmax(-1)  # Get predicted classes\n",
        "\n",
        "# Compute evaluation metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_val, preds))\n",
        "print(\n",
        "    classification_report(\n",
        "        y_val,\n",
        "        preds,\n",
        "        target_names=[\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "R7T-4u_KuKT-",
        "outputId": "f3a91612-30cc-4c17-b1c1-85867d76a6ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-28-26f8022ff3c1>:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "<ipython-input-28-26f8022ff3c1>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9564' max='9564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9564/9564 10:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.927400</td>\n",
              "      <td>0.929026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.760800</td>\n",
              "      <td>0.889293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.634900</td>\n",
              "      <td>0.942031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-26f8022ff3c1>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-28-26f8022ff3c1>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-28-26f8022ff3c1>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-28-26f8022ff3c1>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6378607277289837\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "         Negative       0.53      0.44      0.48       813\n",
            "Somewhat Negative       0.63      0.67      0.65      3207\n",
            "          Neutral       0.66      0.64      0.65      3877\n",
            "Somewhat Positive       0.66      0.69      0.67      3768\n",
            "         Positive       0.58      0.51      0.54      1087\n",
            "\n",
            "         accuracy                           0.64     12752\n",
            "        macro avg       0.61      0.59      0.60     12752\n",
            "     weighted avg       0.64      0.64      0.64     12752\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "# Load the GPT2 tokenizer and model\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
        "\n",
        "# set Padding Token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Data preprocessing function\n",
        "def preprocess_function(texts, labels=None, max_len=128):\n",
        "    encodings = tokenizer(\n",
        "        list(texts),\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    if labels is not None:\n",
        "        encodings[\"labels\"] = torch.tensor(list(labels), dtype=torch.long)\n",
        "    return encodings\n",
        "\n",
        "# using the cleaned dataset\n",
        "train_encodings = preprocess_function(X_train, y_train, max_len=128)\n",
        "val_encodings = preprocess_function(X_val, y_val, max_len=128)\n",
        "\n",
        "# Define custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings)\n",
        "val_dataset = CustomDataset(val_encodings)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Define Trainer arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./gpt2_logs\",\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "kgIalLoA1Fo_",
        "outputId": "d9cacc53-372e-4ce1-b28c-ac80d256ab7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-31-247096d681b8>:74: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19128' max='19128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19128/19128 16:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.072400</td>\n",
              "      <td>0.981343</td>\n",
              "      <td>0.588457</td>\n",
              "      <td>0.589023</td>\n",
              "      <td>0.588457</td>\n",
              "      <td>0.581645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.825600</td>\n",
              "      <td>0.936919</td>\n",
              "      <td>0.609395</td>\n",
              "      <td>0.606210</td>\n",
              "      <td>0.609395</td>\n",
              "      <td>0.603755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.681300</td>\n",
              "      <td>0.944515</td>\n",
              "      <td>0.607748</td>\n",
              "      <td>0.605373</td>\n",
              "      <td>0.607748</td>\n",
              "      <td>0.604371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1594' max='1594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1594/1594 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.9369191527366638, 'eval_accuracy': 0.6093946047678795, 'eval_precision': 0.6062095339221956, 'eval_recall': 0.6093946047678795, 'eval_f1': 0.603755266881116, 'eval_runtime': 22.903, 'eval_samples_per_second': 556.783, 'eval_steps_per_second': 69.598, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the validation set using the trained model\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)  # Get predicted classes\n",
        "\n",
        "# Print the shape of the predictions (to check alignment)\n",
        "print(\"Predictions shape:\", preds.shape)\n",
        "\n",
        "# Print the shape of the validation labels\n",
        "print(\"Validation labels shape:\", np.array(y_val).shape)\n",
        "\n",
        "# Ensure predictions and true labels are aligned\n",
        "if len(preds) < len(y_val):\n",
        "    y_val = y_val[:len(preds)]\n",
        "elif len(preds) > len(y_val):\n",
        "    preds = preds[:len(y_val)]\n",
        "\n",
        "# Output classification report\n",
        "report = classification_report(\n",
        "    y_val, preds, target_names=[\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]\n",
        ")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Output overall accuracy\n",
        "accuracy = accuracy_score(y_val, preds)\n",
        "print(\"Overall Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OAFV84dL6Ixy",
        "outputId": "e92cde7c-82c3-4512-e36b-8db049cf917f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (12752,)\n",
            "Validation labels shape: (12752,)\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "         Negative       0.51      0.34      0.41       813\n",
            "Somewhat Negative       0.59      0.61      0.60      3207\n",
            "          Neutral       0.63      0.65      0.64      3877\n",
            "Somewhat Positive       0.61      0.69      0.65      3768\n",
            "         Positive       0.58      0.36      0.45      1087\n",
            "\n",
            "         accuracy                           0.61     12752\n",
            "        macro avg       0.59      0.53      0.55     12752\n",
            "     weighted avg       0.61      0.61      0.60     12752\n",
            "\n",
            "Overall Accuracy: 0.6093946047678795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the uncleaned dataset\n",
        "# Load BERT model\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels=5)\n",
        "\n",
        "# Define Trainer arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_results\",\n",
        "    run_name=\"bert_finetune_experiment\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./bert_logs\",\n",
        ")\n",
        "\n",
        "# Define dataset format\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "train_dataset1 = CustomDataset(train_encodings)\n",
        "val_dataset1 = CustomDataset(val_encodings)\n",
        "\n",
        "# Initialize Trainer\n",
        "bert_trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset1,\n",
        "    eval_dataset=val_dataset1,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "bert_trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "24Mwf46Gjr1p",
        "outputId": "4ffe2af0-cb88-4d3d-b221-8a8cc1a848fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myscz\u001b[0m (\u001b[33myscz-northeastern-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241205_180405-nco6ewe4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yscz-northeastern-university/huggingface/runs/nco6ewe4' target=\"_blank\">bert_finetune_experiment</a></strong> to <a href='https://wandb.ai/yscz-northeastern-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yscz-northeastern-university/huggingface' target=\"_blank\">https://wandb.ai/yscz-northeastern-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yscz-northeastern-university/huggingface/runs/nco6ewe4' target=\"_blank\">https://wandb.ai/yscz-northeastern-university/huggingface/runs/nco6ewe4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-73e8d4eab3d0>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2928' max='2928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2928/2928 11:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.880200</td>\n",
              "      <td>0.721229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.682200</td>\n",
              "      <td>0.706213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.624500</td>\n",
              "      <td>0.712110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-73e8d4eab3d0>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-3-73e8d4eab3d0>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-3-73e8d4eab3d0>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2928, training_loss=0.7078721093349769, metrics={'train_runtime': 674.5333, 'train_samples_per_second': 555.264, 'train_steps_per_second': 4.341, 'total_flos': 4.927466077551821e+16, 'train_loss': 0.7078721093349769, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the validation set\n",
        "bert_predictions = bert_trainer.predict(val_dataset1)\n",
        "bert_preds = bert_predictions.predictions.argmax(-1)  # Get predicted classes\n",
        "\n",
        "# Extract validation labels from encoded data\n",
        "val_labels = val_encodings[\"labels\"].tolist()  # Ensure labels align with the validation set\n",
        "\n",
        "# Check the size of validation labels and predictions\n",
        "print(\"Number of validation samples:\", len(val_labels))\n",
        "print(\"Number of predictions:\", len(bert_preds))\n",
        "\n",
        "# Align predictions and true labels\n",
        "if len(bert_preds) < len(val_labels):\n",
        "    val_labels = val_labels[:len(bert_preds)]\n",
        "elif len(bert_preds) > len(val_labels):\n",
        "    bert_preds = bert_preds[:len(val_labels)]\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Accuracy:\", accuracy_score(val_labels, bert_preds))  # Output accuracy\n",
        "print(classification_report(val_labels, bert_preds, target_names=[\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "A1cN5-Z57D3t",
        "outputId": "a8eb5a3a-7e41-4619-8330-5f6d6a9085ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-73e8d4eab3d0>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "验证集样本数: 31212\n",
            "预测结果数: 31212\n",
            "Accuracy: 0.7036716647443291\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "         Negative       0.55      0.50      0.52      1416\n",
            "Somewhat Negative       0.60      0.63      0.62      5527\n",
            "          Neutral       0.80      0.80      0.80     15639\n",
            "Somewhat Positive       0.64      0.62      0.63      6707\n",
            "         Positive       0.57      0.62      0.59      1923\n",
            "\n",
            "         accuracy                           0.70     31212\n",
            "        macro avg       0.63      0.63      0.63     31212\n",
            "     weighted avg       0.70      0.70      0.70     31212\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# using the uncleaned dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_data[\"Phrase\"],\n",
        "    train_data[\"Sentiment\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "def preprocess_function(texts, labels=None, max_len=128):\n",
        "    encodings = tokenizer(\n",
        "        list(texts),\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    if labels is not None:\n",
        "        encodings[\"labels\"] = torch.tensor(list(labels), dtype=torch.long)\n",
        "    return encodings\n",
        "\n",
        "\n",
        "train_encodings = preprocess_function(X_train, y_train, max_len=128)\n",
        "val_encodings = preprocess_function(X_val, y_val, max_len=128)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings)\n",
        "val_dataset = CustomDataset(val_encodings)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./gpt2_logs\",\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", results)\n",
        "\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = torch.argmax(torch.tensor(predictions.predictions), dim=-1)\n",
        "report = classification_report(\n",
        "    y_val, preds.numpy(), target_names=[\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]\n",
        ")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "lL9P1VoY6rNW",
        "outputId": "57095081-ee17-4734-832b-c66f98e52824"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-34-66dedcc91213>:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46818' max='46818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [46818/46818 41:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.919200</td>\n",
              "      <td>0.764746</td>\n",
              "      <td>0.688806</td>\n",
              "      <td>0.681548</td>\n",
              "      <td>0.688806</td>\n",
              "      <td>0.674943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.783300</td>\n",
              "      <td>0.742043</td>\n",
              "      <td>0.696847</td>\n",
              "      <td>0.692453</td>\n",
              "      <td>0.696847</td>\n",
              "      <td>0.692914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.668900</td>\n",
              "      <td>0.763674</td>\n",
              "      <td>0.696367</td>\n",
              "      <td>0.694510</td>\n",
              "      <td>0.696367</td>\n",
              "      <td>0.695097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.7420432567596436, 'eval_accuracy': 0.6968473663975394, 'eval_precision': 0.6924528072449029, 'eval_recall': 0.6968473663975394, 'eval_f1': 0.6929139269443868, 'eval_runtime': 55.4307, 'eval_samples_per_second': 563.082, 'eval_steps_per_second': 70.394, 'epoch': 3.0}\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "         Negative       0.61      0.37      0.46      1416\n",
            "Somewhat Negative       0.60      0.61      0.60      5527\n",
            "          Neutral       0.77      0.82      0.79     15639\n",
            "Somewhat Positive       0.63      0.60      0.61      6707\n",
            "         Positive       0.58      0.57      0.57      1923\n",
            "\n",
            "         accuracy                           0.70     31212\n",
            "        macro avg       0.64      0.59      0.61     31212\n",
            "     weighted avg       0.69      0.70      0.69     31212\n",
            "\n"
          ]
        }
      ]
    }
  ]
}